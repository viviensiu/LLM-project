{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6d93b8-9789-4f29-b568-bdbf7de4e8bf",
   "metadata": {},
   "source": [
    "# Hybrid Search with Document Reranking\n",
    "\n",
    "This notebook aims to explore if the performance of hybrid search can be further improved using document reranking.\n",
    "\n",
    "The best hybrid search method concluded from notebook `retrieval_evaluation.ipynb` would be used here as a baseline, then a hybrid search with document reranking would be setup and evaluated alongside the baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc14883d-1f59-4d13-a24c-ebdeb21874eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d6b09-f6b3-40be-8a65-0e820a51ca5e",
   "metadata": {},
   "source": [
    "## Index data into Elasticsearch\n",
    "\n",
    "Reindexing data in case anyone is running this notebook standalone (not following the project flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d1824b-3d5a-4a3a-b0f8-6c2b786d2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data/\"\n",
    "documents_file = \"az900_notes_with_vectors.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c890b9a-752a-45c0-8dd9-0645c85e62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{folder}{documents_file}\").set_index(\"doc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202f5101-c368-4226-b0d5-404f1414f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viviensiew/.local/share/virtualenvs/LLM-project-84bUGCVP/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/all-MiniLM-L12-v2'\n",
    "vec_dim = SentenceTransformer(model_name).get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13809ac5-1295-4086-9de7-a709b911fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_es_mapping(df, vec_dim):\n",
    "    '''\n",
    "    Accepts a pandas dataframe and vector embedding dimension and generates elasticsearch index mapping properties dynamically.\n",
    "    Index is keyword type.\n",
    "    Fields end with \"_vec\" are dense vector types, while others are text types.\n",
    "    '''\n",
    "    similarity = 'cosine'    \n",
    "    es_mapping = {}\n",
    "\n",
    "    if type(df.index) == pd.Index :\n",
    "        es_mapping[df.index.name] = {'type': 'keyword'}\n",
    "        \n",
    "    # for col, dtype in df.dtypes.iteritems():\n",
    "    for col in df.columns:\n",
    "        if col.endswith(\"_vec\"):\n",
    "            es_mapping[col] = {'type': 'dense_vector', 'dims': vec_dim, 'index': True, 'similarity':similarity}\n",
    "        else:\n",
    "            es_mapping[col] = {'type': 'text'}\n",
    "    return es_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abc4cfb-5810-458c-a80b-8a08e2c49c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_mapping_properties = infer_es_mapping(df, vec_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36324648-6188-4ec9-854c-1edd65d260d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6032d8-0e84-43ca-ad1c-812967eb2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_index(es_mapping_properties, index_name):\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": es_mapping_properties\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "    es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e67050-8ab0-4931-bef3-3285021fbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_index_name = \"az900_course_notes\"\n",
    "create_es_index(es_mapping_properties, es_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36dcd38a-4eff-48e0-9946-f8db7f2950d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f965755a106d4a3cb69c4e11c742df3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = pd.read_pickle(f\"{folder}{documents_file}\").to_dict(orient=\"records\")\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=es_index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba7603-b635-413a-a98f-901b9f36b68c",
   "metadata": {},
   "source": [
    "## Load ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d70535b-adb8-43b5-9f1a-18c217db3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_file = \"ground-truth-data.pkl\"\n",
    "ground_truth = pd.read_pickle(f\"{folder}{ground_truth_file}\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c80a81-4184-4e1b-9ccb-abdeaf118172",
   "metadata": {},
   "source": [
    "### Setup Hybrid search (no reranking)\n",
    "\n",
    "As mentioned, this would be the baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e916c154-4270-422b-b274-d848f57e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_hybrid_search(question, question_vec, index_name, boost=0.05):\n",
    "    keyword_query = {\"query\": question,\n",
    "                    \"fields\": [\"header\", \"subheader\", \"doc_text\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": boost,\n",
    "                    }\n",
    "\n",
    "    vector_query = {\"query\": {\"match_all\": {}},\n",
    "                    \"script\": {\n",
    "                                \"source\": \"\"\"\n",
    "                                    0.2 * cosineSimilarity(params.query_vector, 'header_vec') + \n",
    "                                    0.2 * cosineSimilarity(params.query_vector, 'subheader_vec') + \n",
    "                                    0.6 * cosineSimilarity(params.query_vector, 'doc_text_vec') + 1\n",
    "                                \"\"\",\n",
    "                                \"params\": {\"query_vector\": question_vec}\n",
    "                            }\n",
    "                   }\n",
    "    \n",
    "    hybrid_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [{\"multi_match\": keyword_query},\n",
    "                     {\"script_score\": vector_query}\n",
    "                    ]\n",
    "            },\n",
    "        }\n",
    "\n",
    "    search_query = {\n",
    "        \"query\": hybrid_query,\n",
    "        \"size\": 5,\n",
    "        \"_source\": ['doc_id', 'header', 'suheader', 'document', 'doc_text']\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926da70-dd32-4a25-b380-e30e9600c07d",
   "metadata": {},
   "source": [
    "### Setup Hybrid Search with Document Reranking using Reciprocal Rank Fusion (RRF)\n",
    "\n",
    "* For text-based search and vector-search, retrieve a set of top 10 results separately.\n",
    "* For each set of results, rerank the documents using RRF method.\n",
    "* Return the top 5 results from reranked documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc880cb-58a1-4c12-9b91-b2b3a47e0dea",
   "metadata": {},
   "source": [
    "### How RRF works\n",
    "\n",
    "Basically for each document that appears in the search result, each appearance is scored by computing its rrf (relevance using its rank).\n",
    "A document could appear more than once in the search result, hence the score could be boosted by incrementing each individual appearance's rrf.\n",
    "\n",
    "The RRF is used to rerank the search results for a **single query**:\n",
    "\n",
    "* Retrieve text-based results using ES search with `text_search_query`.\n",
    "* Retrieve vector-based results using ES search with `vector_search_query`.\n",
    "* Initialise an empty dictonary `rrf_score` which stores key-value pairs of `_id` : `score`, `_id` is the unique ES index that is generated during indexing and not the doc_id.\n",
    "* For each result in vector-based results (which is already sorted in top 10 results):\n",
    "    * Compute the rrf score.\n",
    "    * Write a key-value pair of `_id` : `score` into the dictonary `rrf_score`.\n",
    "* For each result in text-based results (which is already sorted in top 10 results):\n",
    "    * Compute the `rrf score`.\n",
    "    * If `rrf_score[_id]` exists already, increment its rrf score, else write a key-value pair of `_id` : `score` into the dictonary rrf_score.\n",
    "* Reorder the dictonary `rrf_score` based on `score` and return only the top 5 results' `doc_id` and `_source` for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a5105a-ce28-4c9c-807b-3747ac5d634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rrf(rank, k=60):\n",
    "    \"\"\" Our own implementation of the relevance score \"\"\"\n",
    "    return 1 / (k + rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f91748-b451-4f57-b7f3-27a47df9b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_hybrid_search_rrf(question, question_vec, index_name, k=10):    \n",
    "    text_search_query = {\n",
    "        \"size\":10,\n",
    "        \"query\" :{\n",
    "        \"bool\": {\n",
    "            \"must\": {\"multi_match\": {\"query\": question,\n",
    "                    \"fields\": [\"header\", \"subheader\", \"doc_text\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.05,\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    vector_search_query = {\n",
    "        \"size\": 10,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"query\": {\n",
    "                                \"match_all\": {},\n",
    "                            },\n",
    "                            \"script\": {\n",
    "                                \"source\": \"\"\"\n",
    "                                    0.2 * cosineSimilarity(params.query_vector, 'header_vec') + \n",
    "                                    0.2 * cosineSimilarity(params.query_vector, 'subheader_vec') + \n",
    "                                    0.6 * cosineSimilarity(params.query_vector, 'doc_text_vec') + 1\n",
    "                                \"\"\",\n",
    "                                \"params\": {\n",
    "                                    \"query_vector\": question_vec\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    text_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=text_search_query\n",
    "    )['hits']['hits']\n",
    "\n",
    "    vector_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=vector_search_query\n",
    "    )['hits']['hits']\n",
    "    \n",
    "\n",
    "    rrf_scores = {}\n",
    "    # Calculate RRF using vector search results\n",
    "    for rank, hit in enumerate(vector_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Adding text search result scores\n",
    "    for rank, hit in enumerate(text_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-5 documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = es_client.get(index=index_name, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8fe54-299f-4673-a953-c2dfb9175df4",
   "metadata": {},
   "source": [
    "### Setup Hit Rate and MRR evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e3b622-235e-49b2-a8ab-a0e688374942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    relevant_count = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            relevant_count = relevant_count + 1\n",
    "\n",
    "    return relevant_count / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903537a2-8338-49bb-a337-dccd8038c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "                break\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f518e0f-af82-494f-bb50-f38f652035a3",
   "metadata": {},
   "source": [
    "Setup a dictionary to store Hit Rate and MRR of each evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b883fb73-e7d4-4675-9e4c-d8eabbe94243",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edb031-c728-405b-ae11-4e9cd56015c4",
   "metadata": {},
   "source": [
    "### Evaluate hybrid search baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07121c6b-abd3-4db8-b780-404b4c078461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5897872ba8a41c98bcdde2aba068053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['doc_id']\n",
    "    results = es_hybrid_search(question=q['question'], question_vec=q['question_vec'], index_name=es_index_name)\n",
    "    relevance = [d['doc_id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b91ab0-5258-4f0c-9f59-4ad5010cb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_hit_rate = hit_rate(relevance_total)\n",
    "hybrid_mrr = mrr(relevance_total)\n",
    "evaluation_dict['hybrid_search_baseline'] = { 'hit_rate': hybrid_hit_rate,\n",
    "                                         'mrr': hybrid_mrr}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0481d-e3b1-48dc-b243-0a4ac2e98379",
   "metadata": {},
   "source": [
    "### Evaluate hybrid search with document reranking using RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3716406-20ad-49ca-8286-5e85c9e3dde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbcaea3efb24370bf6b0893b5b5ec4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['doc_id']\n",
    "    results = es_hybrid_search_rrf(question=q['question'], question_vec=q['question_vec'], index_name=es_index_name)\n",
    "    relevance = [d['doc_id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31eb210b-801a-4484-8417-752300c9d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_rrf_hit_rate = hit_rate(relevance_total)\n",
    "hybrid_rrf_mrr = mrr(relevance_total)\n",
    "evaluation_dict['hybrid_search_rrf'] = { 'hit_rate': hybrid_rrf_hit_rate,\n",
    "                                         'mrr': hybrid_rrf_mrr}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375309f-c8f0-4ed3-abc6-fb6bd2e84646",
   "metadata": {},
   "source": [
    "### Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5913d691-a818-4262-9b12-0f2b8a5a5691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid_search_baseline</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.682641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid_search_rrf</td>\n",
       "      <td>0.830649</td>\n",
       "      <td>0.650658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index  hit_rate       mrr\n",
       "0  hybrid_search_baseline  0.851429  0.682641\n",
       "1       hybrid_search_rrf  0.830649  0.650658"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(evaluation_dict).T\n",
    "df_eval.reset_index().sort_values(by=['hit_rate','mrr'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc5343aa-4bd1-4d5e-830f-4172b6d277b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid_search_baseline</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.682641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid_search_rrf</td>\n",
       "      <td>0.830649</td>\n",
       "      <td>0.650658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index  hit_rate       mrr\n",
       "0  hybrid_search_baseline  0.851429  0.682641\n",
       "1       hybrid_search_rrf  0.830649  0.650658"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.reset_index().sort_values(by=['hit_rate'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e6f802f-cd62-49ab-bf97-1ec54a630bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid_search_baseline</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.682641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid_search_rrf</td>\n",
       "      <td>0.830649</td>\n",
       "      <td>0.650658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index  hit_rate       mrr\n",
       "0  hybrid_search_baseline  0.851429  0.682641\n",
       "1       hybrid_search_rrf  0.830649  0.650658"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.reset_index().sort_values(by=['mrr'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bd408-9b3b-4958-b8ba-fea35480e7a2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2792f-64fe-4a18-ac13-0002d3dc9da0",
   "metadata": {},
   "source": [
    "The reranking did not fare better compared to the baseline, hence the retrieval method to be used in the RAG application would remain to be the hybrid search baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
